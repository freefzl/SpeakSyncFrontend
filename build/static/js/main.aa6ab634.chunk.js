(this["webpackJsonpmultilingual-voice-chat"]=this["webpackJsonpmultilingual-voice-chat"]||[]).push([[0],{101:function(e,t,a){"use strict";a.r(t);var n=a(0),r=a(10),c=a.n(r),o=a(52),s=a(13),i=a(152),l=a(153),d=a(135),u=a(137),b=a(139),j=a(61),g=a(159),m=a(142),h=a(161),p=a(154),O=a(145),x=a(146),y=a(144),f=a(103),v=a(147),w=a(148),S=a(157),k=a(149),C=a(150),R=a(155),$=a(49),A=a.n($),N=a(2);const L=Object(d.a)((e=>({root:{marginTop:e.spacing(4),padding:e.spacing(3),maxWidth:800,margin:"0 auto"},form:{width:"100%",marginTop:e.spacing(3)},submit:{margin:e.spacing(3,0,2)},formControl:{width:"100%"},heading:{marginBottom:e.spacing(3)},features:{marginTop:e.spacing(4)},faq:{marginTop:e.spacing(4)},accordion:{marginBottom:e.spacing(1)},featureList:{backgroundColor:e.palette.background.paper,borderRadius:e.shape.borderRadius,marginTop:e.spacing(2)}})));var T=()=>{const e=L(),t=Object(s.f)(),[a,r]=Object(n.useState)(""),[c,o]=Object(n.useState)("en");return Object(N.jsx)(u.a,{className:e.root,children:Object(N.jsxs)(b.a,{container:!0,spacing:3,children:[Object(N.jsxs)(b.a,{item:!0,xs:12,children:[Object(N.jsx)(j.a,{component:"h1",variant:"h4",align:"center",className:e.heading,children:"Real-time Multilingual Voice Chat Room"}),Object(N.jsx)(j.a,{variant:"subtitle1",align:"center",color:"textSecondary",gutterBottom:!0,children:"Break language barriers with real-time voice translation in multiple languages"})]}),Object(N.jsx)(b.a,{item:!0,xs:12,children:Object(N.jsx)("form",{className:e.form,onSubmit:e=>{e.preventDefault(),a.trim()&&t.push(`/room/${a}?language=${c}`)},children:Object(N.jsxs)(b.a,{container:!0,spacing:3,children:[Object(N.jsx)(b.a,{item:!0,xs:12,children:Object(N.jsx)(g.a,{required:!0,fullWidth:!0,label:"Room ID",value:a,onChange:e=>r(e.target.value),variant:"outlined",placeholder:"Enter room ID or create a new room"})}),Object(N.jsx)(b.a,{item:!0,xs:12,children:Object(N.jsxs)(m.a,{variant:"outlined",className:e.formControl,children:[Object(N.jsx)(h.a,{children:"Select Language"}),Object(N.jsxs)(p.a,{value:c,onChange:e=>o(e.target.value),label:"Select Language",children:[Object(N.jsx)(O.a,{value:"en",children:"English"}),Object(N.jsx)(O.a,{value:"zh",children:"Chinese"}),Object(N.jsx)(O.a,{value:"ja",children:"Japanese"}),Object(N.jsx)(O.a,{value:"ru",children:"Russian"}),Object(N.jsx)(O.a,{value:"fr",children:"French"}),Object(N.jsx)(O.a,{value:"de",children:"German"}),Object(N.jsx)(O.a,{value:"es",children:"Spanish"}),Object(N.jsx)(O.a,{value:"pt",children:"Portuguese"}),Object(N.jsx)(O.a,{value:"it",children:"Italian"})]})]})}),Object(N.jsx)(b.a,{item:!0,xs:12,children:Object(N.jsx)(x.a,{type:"submit",fullWidth:!0,variant:"contained",color:"primary",className:e.submit,children:"Join Room"})})]})})}),Object(N.jsxs)(b.a,{item:!0,xs:12,className:e.features,children:[Object(N.jsx)(j.a,{variant:"h5",gutterBottom:!0,children:"Key Features"}),Object(N.jsxs)(y.a,{className:e.featureList,children:[Object(N.jsx)(f.a,{children:Object(N.jsx)(v.a,{primary:"Real-time Voice Translation",secondary:"Instantly translate your voice into multiple languages"})}),Object(N.jsx)(w.a,{}),Object(N.jsx)(f.a,{children:Object(N.jsx)(v.a,{primary:"Multiple Language Support",secondary:"Support for English, Chinese, Japanese, Russian, French, German, Spanish, and more"})}),Object(N.jsx)(w.a,{}),Object(N.jsx)(f.a,{children:Object(N.jsx)(v.a,{primary:"High-Quality Voice Synthesis",secondary:"Natural-sounding voice output in target languages"})}),Object(N.jsx)(w.a,{}),Object(N.jsx)(f.a,{children:Object(N.jsx)(v.a,{primary:"Easy Room Creation",secondary:"Create or join rooms with simple room IDs"})})]})]}),Object(N.jsxs)(b.a,{item:!0,xs:12,className:e.faq,children:[Object(N.jsx)(j.a,{variant:"h5",gutterBottom:!0,children:"Frequently Asked Questions"}),Object(N.jsxs)(S.a,{className:e.accordion,children:[Object(N.jsx)(k.a,{expandIcon:Object(N.jsx)(A.a,{}),children:Object(N.jsx)(j.a,{variant:"subtitle1",children:"How does it work?"})}),Object(N.jsx)(C.a,{children:Object(N.jsx)(j.a,{children:"The system uses advanced speech recognition to convert your voice into text, translates it into the target language, and then converts it back to speech in real-time. All participants in the room can hear the conversation in their chosen language."})})]}),Object(N.jsxs)(S.a,{className:e.accordion,children:[Object(N.jsx)(k.a,{expandIcon:Object(N.jsx)(A.a,{}),children:Object(N.jsx)(j.a,{variant:"subtitle1",children:"Is my conversation secure?"})}),Object(N.jsx)(C.a,{children:Object(N.jsx)(j.a,{children:"All voice data is processed in real-time and is not stored on our servers. The communication is handled through secure WebSocket connections."})})]}),Object(N.jsxs)(S.a,{className:e.accordion,children:[Object(N.jsx)(k.a,{expandIcon:Object(N.jsx)(A.a,{}),children:Object(N.jsx)(j.a,{variant:"subtitle1",children:"What devices are supported?"})}),Object(N.jsx)(C.a,{children:Object(N.jsx)(j.a,{children:"The system works on any modern web browser that supports WebRTC and microphone access. This includes Chrome, Firefox, Safari, and Edge on both desktop and mobile devices."})})]}),Object(N.jsxs)(S.a,{className:e.accordion,children:[Object(N.jsx)(k.a,{expandIcon:Object(N.jsx)(A.a,{}),children:Object(N.jsx)(j.a,{variant:"subtitle1",children:"How many people can join a room?"})}),Object(N.jsx)(C.a,{children:Object(N.jsx)(j.a,{children:"Multiple users can join the same room and communicate in different languages simultaneously. Each user can select their preferred language for both speaking and listening."})})]})]}),Object(N.jsx)(b.a,{item:!0,xs:12,children:Object(N.jsx)(R.a,{mt:4,textAlign:"center",children:Object(N.jsx)(j.a,{variant:"body2",color:"textSecondary",children:"Start breaking language barriers today with our real-time voice translation technology."})})})]})})},W=a(158),E=a(151),I=a(156);const B=Object(d.a)((e=>({root:{padding:e.spacing(3),marginTop:e.spacing(3)},statusPaper:{padding:e.spacing(2),marginTop:e.spacing(2),backgroundColor:e.palette.background.default},button:{margin:e.spacing(1)},audioStatus:{marginTop:e.spacing(2),padding:e.spacing(1),backgroundColor:e.palette.info.light,color:e.palette.info.contrastText,borderRadius:e.shape.borderRadius}}))),z=Object(n.forwardRef)(((e,t)=>Object(N.jsx)(I.a,{elevation:6,ref:t,variant:"filled",...e}))),D=Object(n.forwardRef)(((e,t)=>{let{open:a,onClose:n,severity:r,message:c}=e;return Object(N.jsx)(W.a,{open:a,autoHideDuration:6e3,onClose:n,ref:t,children:Object(N.jsx)(z,{onClose:n,severity:r,children:c})})}));var M=()=>{const e=B(),t=Object(s.g)(),a=t.pathname.split("/")[2]||"",r=new URLSearchParams(t.search).get("language")||"en",[c,o]=Object(n.useState)(!1),[i,l]=Object(n.useState)(null),[d,g]=Object(n.useState)("disconnected"),[m,h]=Object(n.useState)(!1),[p,O]=Object(n.useState)(!1),[y,f]=Object(n.useState)("info"),[v,w]=Object(n.useState)([]),[S,k]=Object(n.useState)(!0),[C,R]=Object(n.useState)(0),[$,A]=Object(n.useState)(0),[L,T]=Object(n.useState)(""),W=Object(n.useRef)(null),I=Object(n.useRef)(null),z=Object(n.useRef)(null),M=Object(n.useRef)(null),U=Object(n.useRef)([]),P=Object(n.useRef)(!1),F=Object(n.useRef)(null),_=Object(n.useCallback)((e=>{w((t=>[...t,{time:(new Date).toLocaleTimeString(),message:e}].slice(-10)))}),[]),J=Object(n.useCallback)(((e,t)=>{l(e),f(t),O(!0)}),[]),H=Object(n.useCallback)((()=>{z.current&&(z.current.getTracks().forEach((e=>e.stop())),_("Cleanup: Closing audio stream")),I.current&&(I.current.stop(),_("Cleanup: Stopping recorder")),W.current&&(W.current.close(),_("Cleanup: Closing WebSocket connection")),M.current&&(M.current.close(),_("Cleanup: Closing audio context")),U.current=[],P.current=!1,R(0)}),[_]),G=Object(n.useCallback)((async e=>{try{if(h(!0),_(`Preparing to play audio data (size: ${e.size} bytes)`),0===e.size)return _("Warning: Received empty audio data"),void h(!1);if(M.current&&"closed"!==M.current.state||(M.current=new(window.AudioContext||window.webkitAudioContext),_("Created new AudioContext")),"suspended"===M.current.state)try{await M.current.resume(),_("Automatic audio context restoration successful")}catch(t){_(`Automatic audio context restoration failed: ${t.message}`),J("Please click the page to enable audio playback","info")}const n=new Audio,r=URL.createObjectURL(e);n.src=r,n.onerror=t=>{_(`Audio load error: ${t.target.error}`),h(!1),URL.revokeObjectURL(r),q(e)},n.onended=()=>{h(!1),URL.revokeObjectURL(r),_("Audio playback completed")};try{await n.play(),_("Starting audio playback")}catch(a){_(`Direct playback failed, trying fallback: ${a.message}`),URL.revokeObjectURL(r),await q(e)}R((e=>e+1))}catch(t){console.error("Audio playback failed:",t),h(!1),_(`Audio playback failed: ${t.message}`),J("Audio playback error, trying to restore...","warning")}}),[_,J]),q=async e=>{try{_("Using fallback to play audio"),M.current&&"closed"!==M.current.state||(M.current=new(window.AudioContext||window.webkitAudioContext)),"suspended"===M.current.state&&await M.current.resume();const a=await e.arrayBuffer();try{const e=await M.current.decodeAudioData(a);_(`Audio decoding successful: ${e.duration.toFixed(2)} seconds`);const t=M.current.createBufferSource();t.buffer=e,t.connect(M.current.destination),t.onended=()=>{h(!1),_("Fallback playback completed")},t.start(0),_("Fallback playback started")}catch(t){throw _(`Audio decoding failed: ${t.message}`),t}}catch(i){_(`Fallback playback failed: ${i.message}`),h(!1),J("Audio playback failed","error")}},V=Object(n.useCallback)((()=>{if(!a)return l("Please enter Room ID"),g("error"),void _("Error: Room ID not provided");try{g("connecting"),_("Connecting WebSocket...");const e=`ws://18.188.212.216:8000/ws/${a}?language=${r}`;_(`Connecting WebSocket: ${e}`);const t=new WebSocket(e);W.current=t,t.onopen=()=>{g("connected"),J("Connected to chat room","success"),_("WebSocket connection successful");const e={type:"join",room_id:a,language:r,client_id:Math.random().toString(36).substring(7)};t.send(JSON.stringify(e)),_(`Sent join room message: ${JSON.stringify(e)}`)},t.onmessage=async e=>{try{const a=JSON.parse(e.data);switch(_(`Received message type: ${a.type}`),a.type){case"audio":try{if(!a.audio_data)return void _("Warning: Received empty audio data");const e=atob(a.audio_data),t=new Uint8Array(e.length);for(let a=0;a<e.length;a++)t[a]=e.charCodeAt(a);const n=new Blob([t.buffer],{type:"audio/mp3"});_(`Created audio Blob: ${n.size} bytes`),n.size>0?await G(n):_("Warning: Generated audio Blob is empty")}catch(t){_(`Audio data processing error: ${t.message}`)}break;case"text":T(a.content),_(`Received translation text: ${a.content}`);break;case"room_info":A(a.members_count),_(`Room member count updated: ${a.members_count}`);break;case"error":_(`Received error message: ${a.message}`),J(a.message,"error");break;default:_(`Received unknown type message: ${a.type}`)}}catch(t){_(`Error processing message: ${t.message}\n${t.stack}`),console.error("Message processing error:",t)}},t.onerror=e=>{console.error("WebSocket error:",e),l("WebSocket connection error"),g("error"),J("Connection error","error"),_(`WebSocket error: ${e.message||"Unknown error"}`)},t.onclose=e=>{g("disconnected"),J("Connection closed","warning"),_(`WebSocket connection closed (code: ${e.code})`),R(0),setTimeout((()=>{1e3!==e.code&&(_("Trying to reconnect..."),V())}),3e3)}}catch(e){console.error("Connection error:",e),l("Connection error"),g("error"),_(`Connection error: ${e.message}\n${e.stack}`)}}),[a,r,J,G,_]);return Object(n.useEffect)((()=>(a&&V(),H)),[V,H,a]),Object(n.useEffect)((()=>{const e=async()=>{M.current&&"suspended"===M.current.state&&(await M.current.resume(),_("Lifted audio context restriction through user interaction"))};return window.addEventListener("click",e),window.addEventListener("touchstart",e),()=>{window.removeEventListener("click",e),window.removeEventListener("touchstart",e)}}),[_]),Object(N.jsxs)(b.a,{container:!0,spacing:2,direction:"column",alignItems:"center",children:[Object(N.jsxs)(u.a,{className:e.root,children:[Object(N.jsx)(b.a,{item:!0,children:Object(N.jsxs)(j.a,{variant:"h4",gutterBottom:!0,children:["Room: ",a||"Please enter Room ID in URL"]})}),Object(N.jsx)(b.a,{item:!0,children:Object(N.jsxs)(j.a,{variant:"body1",gutterBottom:!0,children:["Current Language: ",r]})}),Object(N.jsx)(u.a,{className:e.statusPaper,children:Object(N.jsxs)(b.a,{container:!0,spacing:2,alignItems:"center",children:[Object(N.jsx)(b.a,{item:!0,children:Object(N.jsxs)(j.a,{variant:"body2",children:["Status: ",a?d:"Waiting for Room ID"]})}),Object(N.jsx)(b.a,{item:!0,children:Object(N.jsxs)(j.a,{variant:"body2",color:"textSecondary",children:["Current Members: ",$]})}),Object(N.jsx)(b.a,{item:!0,children:"connecting"===d&&Object(N.jsx)(E.a,{size:20})})]})}),Object(N.jsx)(b.a,{item:!0,children:Object(N.jsx)(x.a,{variant:"contained",color:c?"secondary":"primary",onClick:c?()=>{I.current&&"recording"===I.current.state&&(I.current.stop(),_("Stopped recording")),z.current&&(z.current.getTracks().forEach((e=>e.stop())),_("Closed audio stream")),o(!1),J("Stopped recording","info")}:async()=>{try{_("Starting recording initialization...");const e=await navigator.mediaDevices.getUserMedia({audio:{channelCount:1,sampleRate:16e3,sampleSize:16,echoCancellation:!0,noiseSuppression:!0}});z.current=e,_("Successfully obtained microphone permission");const t=new MediaRecorder(e,{mimeType:"audio/webm;codecs=opus",audioBitsPerSecond:16e3});I.current=t,_("MediaRecorder initialization successful");let n=[],c=!1,s=null;t.ondataavailable=e=>{e.data.size>0&&(n.push(e.data),_(`Received audio data chunk: ${e.data.size} bytes`),c||(c=!0,_("Starting to collect audio data")),s&&clearTimeout(s),s=setTimeout((()=>{n.length>0&&(_(`Preparing to process audio data: ${n.length} chunks`),(async e=>{let t=null,n=null;try{var c;_(`Starting to process audio data chunks: ${e.length} chunks`);const o=new Blob(e,{type:"audio/webm;codecs=opus"});if(_(`Created Blob: ${o.size} bytes, type: ${o.type}`),0===o.size)return void _("Warning: Audio data is empty");const s=await o.arrayBuffer();_(`Converted to ArrayBuffer: ${s.byteLength} bytes`),t=new(window.AudioContext||window.webkitAudioContext)({sampleRate:16e3});const i=await t.decodeAudioData(s);_(`Decoded audio data: Duration ${i.duration.toFixed(2)} seconds, Sample Rate ${i.sampleRate}Hz`),n=new OfflineAudioContext(1,Math.ceil(16e3*i.duration),16e3);const l=n.createBufferSource();l.buffer=i,l.connect(n.destination),l.start();const d=await n.startRendering();_(`Resampling completed: ${d.length} samples`);const u=new Float32Array(d.length);d.copyFromChannel(u,0);const b=new Int16Array(u.length),j=1024;for(let e=0;e<u.length;e+=j){const t=Math.min(e+j,u.length);for(let a=e;a<t;a++){const e=Math.max(-1,Math.min(1,u[a]));b[a]=e<0?32768*e:32767*e}}const g=b.buffer,m=new Uint8Array(g);let h="";const p=1024;for(let e=0;e<m.length;e+=p){const t=m.slice(e,e+p);h+=String.fromCharCode.apply(null,t)}const O=btoa(h);if(_(`Converted to Base64: ${O.length} characters`),(null===(c=W.current)||void 0===c?void 0:c.readyState)===WebSocket.OPEN){const e={type:"audio",room_id:a,language:r,audio_data:O,format:"pcm",codec:"pcm",sample_rate:16e3,channels:1,bits_per_sample:16};_(`Preparing to send audio message: ${JSON.stringify({...e,audio_data:`[${O.length} bytes]`})}`),W.current.send(JSON.stringify(e)),_(`Sent audio data: ${g.byteLength} bytes`)}else _(`WebSocket not connected, current status: ${W.current?["CONNECTING","OPEN","CLOSING","CLOSED"][W.current.readyState]:"Not initialized"}`)}catch(o){_(`Audio processing error: ${o.message}\n${o.stack}`),console.error("Audio processing error:",o)}finally{if(t)try{await t.close()}catch(o){_(`Error closing AudioContext: ${o.message}`)}}})([...n]),n=[],c=!1)}),500))},t.start(100),o(!0),_("Starting recording"),J("Starting recording","info")}catch(e){console.error("Recording error:",e),l("Microphone access failed"),_(`Recording error: ${e.message}`),J("Microphone access failed","error")}},className:e.button,disabled:!a||"connected"!==d,children:c?"Stop Speaking":"Start Speaking"})}),m&&Object(N.jsx)("div",{className:e.audioStatus,children:Object(N.jsx)(j.a,{variant:"body2",align:"center",children:"Receiving audio..."})}),L&&Object(N.jsx)("div",{className:e.audioStatus,children:Object(N.jsxs)(j.a,{variant:"body2",align:"center",children:["Translation: ",L]})}),S&&Object(N.jsx)(u.a,{className:e.statusPaper,style:{marginTop:"20px"},children:Object(N.jsxs)(b.a,{container:!0,direction:"column",spacing:1,children:[Object(N.jsxs)(b.a,{item:!0,container:!0,justifyContent:"space-between",alignItems:"center",children:[Object(N.jsxs)(j.a,{variant:"h6",children:["zh"===r?"Sending":"Receiving"," Logs",C>0&&"zh"!==r&&` (Received ${C} chunks)`]}),Object(N.jsx)(x.a,{size:"small",onClick:()=>k(!1),variant:"outlined",children:"Hide Logs"})]}),v.map(((e,t)=>Object(N.jsx)(b.a,{item:!0,children:Object(N.jsxs)(j.a,{variant:"body2",style:{fontFamily:"monospace",color:e.message.includes("error")?"#f44336":e.message.includes("success")?"#4caf50":"inherit"},children:["[",e.time,"] ",e.message]})},t)))]})}),!S&&Object(N.jsx)(x.a,{size:"small",onClick:()=>k(!0),variant:"outlined",style:{marginTop:"20px"},children:"Show Logs"})]}),Object(N.jsx)(D,{ref:F,open:p,onClose:()=>{O(!1)},severity:y,message:i})]})};var U=function(){return Object(N.jsxs)(o.a,{children:[Object(N.jsx)(i.a,{}),Object(N.jsx)(l.a,{maxWidth:"md",children:Object(N.jsxs)(s.c,{children:[Object(N.jsx)(s.a,{exact:!0,path:"/",component:T}),Object(N.jsx)(s.a,{path:"/room/:roomId",component:M})]})})]})};c.a.render(Object(N.jsx)(U,{}),document.getElementById("root"))}},[[101,1,2]]]);
//# sourceMappingURL=main.aa6ab634.chunk.js.map